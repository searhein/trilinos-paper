\todo{work on this after the new products structure is defined}
The discretization product contains several packages to handle discretizations of differential equations.

\subsection{Intrepid2}
Intrepid2 provides interoperable tools for compatible discretizations of PDEs; it is a performance-portable re-implementation and extension of the legacy Intrepid package \cite{bochev2012}. Intrepid2 mainly focuses on local assembly of continuous and discontinuous finite elements. It also provides limited capabilities for finite volume discretization.  Intrepid2 works on batches of elements (cells), and provides tools to efficiently compute discretized linear functionals (e.g., right-hand-side vectors) and differential operators (e.g., stiffness matrices) at the element level. Intrepid2 implements compatible finite element spaces of various polynomial orders for $H({\rm grad})$, $H({\rm curl})$, $H({\rm div})$ and $L^2$ function spaces on triangles, quadrilaterals, tetrahedrons, hexahedrons, wedges and pyramids. It provides both Lagrangian basis functions and hierarchical basis functions \cite{fuentes2015} and it implements performance optimizations (e.g., sum factorizations) exploiting the underlying structure of the problem (e.g., tensor-product elements or other symmetries).  The degrees of freedom of $H({\rm div})$ and $H({\rm curl})$ finite elements, as well as high-order $H({\rm grad})$ finite elements, depend on the global orientation of edges and faces and Intrepid2 provides orientation tools for matching the degrees of freedom on shared edges and faces. It also provides interpolation-based projection tools for projecting functions in $H({\rm grad})$, $H({\rm curl})$, $H({\rm div})$ and $L^2$ to the respective discrete spaces. Intrepid2 implements these capabilities through these classes:
\begin{itemize}
\item \emph{CellTools:} This class provides geometric operations on the reference and physical frame. Includes computation of tangents and normals to edges/faces in the physical frame, computation of Jacobian of the reference-to-physical frame maps, and other metric computations. 
\item \emph{CubatureFactory:} This class provides several quadrature rules (called \emph{cubatures} in Intrepid2) of various degrees of accuracy for approximating integrals over the elements and their boundaries.
\item \emph{Basis:} This is the base class for a variety of basis functions for compatible finite element spaces. Each class includes a \texttt{getValues()} method that computes the value of the basis functions or their derivatives (e.g., gradient for $H({\rm grad})$ functions, curl for $H({\rm curl})$ functions) at a set of input points. The implementation of \texttt{getValues()} can be very different depending on the basis. Specific optimizations are available for tensor-product elements.  Additionally, there is a \texttt{BasisFamily} class with a convenience method, \texttt{getBasis()}, which constructs a basis depending on a template argument specifying the type of basis (hierarchical or nodal, e.g.), the cell topology and function space on which it is defined, and its polynomial degree.
\item \emph{OrientationTools:} This class provides methods to orient the basis functions based on the global orientation of edges and faces, determined by the global numbering of the cell vertices. This is achieved by building a linear operator (a permutation for tensor-product elements) that encodes the orientation of a particular cell, and applying that operator to the reference basis functions.
\item \emph{ProjectionTools:} This class provides methods for interpolation-based projections of a given function into a compatible finite element space or between compatible finite element spaces \cite{demkowicz2007}.  The provided projections commute with the corresponding differential operators if the quadrature rules can exactly integrate the functions being projected. As an example, projecting an $H({\rm grad})$ function into the $H({\rm grad})$ finite-element space and then taking its gradient gives the same result as taking the gradient of the function first, and then projecting the gradient into the $H({\rm curl})$ finite-element space.
\item \emph{FunctionSpaceTools:} This class provides transformations of fields from reference to physical frame and back, computation of measures on edges, faces and cells, scalar/vector/tensor multiplications and contractions for computing integrals.
\item \emph{IntegrationTools:} This class provides integration methods that can take advantage of tensor product structures in basis values, providing mechanisms for performance-portable, \emph{sum-factorized} assembly across $H({\rm grad})$, $H({\rm curl})$, $H({\rm div})$ and $L^2$ function spaces.  In the future, we plan to provide similar interfaces to support matrix-free discretizations.
\end{itemize}
Intrepid2 makes use of Kokkos containers to enable memory layouts that are adapted to the computational platform. Intrepid2 also uses Kokkos for its core computational kernels, enabling threaded execution across a variety of architectures. The data types used by Intrepid2 are templated; it is therefore possible to propagate Sacado types through Intrepid2 to perform automatic differentiation. Current development of Intrepid2 focuses on providing efficient matrix-free discretizations to enhance efficiency on GPU architectures. 

\subsection{Phalanx}
Phalanx is a local field evaluation library designed for equation assembly in partial differential equation (PDE) applications. The goal of Phalanx is to decompose a complex problem into a number of simpler problems with managed dependencies to support rapid development and extensibility of PDE codes \cite{Notz2012,pawlowski2012automating,pawlowski2012automatingpart2}. The data structures use Kokkos \cite{trott2021kokkos} for performance portability. Through the use of template metaprogramming, Phalanx supports arbitrary user defined data types and evaluation types. This feature allows for simple integration of automatic differentiation tools via operator overloaded scalar types from the Sacado library \cite{phipps2022automatic}. From a simple equation definition, quantities such as Jacobians, Jacobian-vector products, Hessians and parameter sensitivities can be evaluated to machine precision. These quantities can be used by other Trilinos packages for operations including Newton-based nonlinear solves, gradient-based optimization, constraint enforcement and bifurcation analysis \cite{pawlowski2012automating,pawlowski2012automatingpart2}.

Phalanx uses a graph-based design to manage data dependencies. The runtime defined directed acyclic graph allows for rapid prototyping in a production environment where simple interfaces for analysts, flexible models/data structures and integration of non-trivial Third-party libraries are paramount. Phalanx is used in a number of large scale parallel codes including Albany \cite{Salinger2016}, Charon \cite{CharonUsersManual2020} Drekar \cite{Crockatt2022,Miller2019,Shadid2016mhd} and EMPIRE \cite{Bettencourt2021}.

In recent years, Phalanx has been extended to provide utilities for performance portability under automatic differentiation. For example, Phalanx provides tools for building and managing a Kokkos view-of-views on device without the use of unified virtual memory and provides utilities for running virtual functions on device. In the future, these utilities may be split out into a separate package.

\subsection{Panzer}
\todo{Roger, please edit/expand}
The package provides global tools for finite element analysis. It handles continuous and discontinuous high-order compatible finite elements, as implemented in Intrepid2 on unstructured meshes. Panzer relies on Phalanx to manage with efficiency and flexibility the assembly of complex problems. Panzer also enables the solution of nonlinear problems, by interfacing with several Trilinos linear and nonlinear solvers. It computes derivatives and sensitivities through automatic differentiation (Sacado). It supports both Epetra and Tpetra data structures and achieves performance portability through the Kokkos programming model.

\subsection{Compadre}
The Compadre package provides tools for the approximation of linear operators (including point evaluation and derivatives), given the location of samples of a function over an unstructured cloud of points. The resulting stencils, when applied directly to samples of the function at these locations, provides an approximation of the linear operator acting on the function at the point(s) queried. This is useful for meshed and meshless data transfer applications. Values of the function at the specified locations can also be viewed as unknowns, in which case the solution returned by Compadre can be used as a stencil for meshless discretization of PDEs. 

The package uses generalized moving least squares (GMLS) for approximating functionals. We plan on implementing other meshless methods like radial basis functions in the future.  A brief description of GMLS follows, but technical details can be found in \cite{mirzaei2012generalized,wendland2004scattered}.

Consider $\phi$ of function class $\mathbf{V}$. Consider a collection of samples $\Lambda = \left\{\lambda_i(\phi)\right\}_{i=1}^{N}$ corresponding to a quasi-uniform\cite{wendland2004scattered} collection of data sites $\mathbf{X}_h = \left\{\mathbf{x}_i\right\} \subset \mathbb{R}^d$ characterized by fill distance $h$. To approximate a given linear target functional $\tau_{\tilde{x}}$ associated with a target site $\tilde{x}$, we seek a reconstruction $p \in \mathbf{V}_h$, where $\mathbf{V}_h \subset \mathbf{V}$ is a finite dimensional space chosen to provide good approximation properties, with basis $\mathbf{P}=\left\{P\right\}_{i=1}^{dim(V_h)}$. We perform this reconstruction in the following weighted $\ell_2$ sense:

\begin{equation}
\label{gmls}
p = \underset{{q \in \mathbf{V}_h}}\argmin \sum_{i=1}^N \left( \lambda_i(\phi) -\lambda_i(q) \right)^2 \omega(\lambda_i,\tau_{\tilde{x}})
\end{equation}
where $\omega$ is a locally supported positive function. Compadre offers several choices for the weighting kernel $\omega = \Phi(|\tilde{x}-\mathbf{x}_i|)$, where $|\cdot|$ denotes the Euclidean norm.

With the optimal reconstruction $p$ computed, the target functional is approximated via $\tau_{\tilde{x}} (\phi) \approx \tau^h_{\tilde{x}} (\phi) := \tau_{\tilde{x}} (p)$. As an unconstrained $\ell_2$-optimization problem, this process admits the explicit form


\begin{equation}
\label{discreteTarget}
\tau^h_{\tilde{x}}(\phi) = \tau_{\tilde{x}}(\mathbf{P})^\intercal \left(\Lambda(\mathbf{P})^\intercal \mathbf{W} \Lambda(\mathbf{P})\right)^{-1} \Lambda(\mathbf{P})^\intercal \mathbf{W} \Lambda(\phi),
\end{equation}
where we denote:
\begin{itemize}
  \item $\tau_{\tilde{x}}(\mathbf{P}) \in \mathbb{R}^{dim(V_h)}$ is a vector with components consisting of the target functional applied to each basis function.
  \item $\mathbf{W} \in \mathbb{R}^{N \times N}$ is a diagonal matrix with diagonal entries consisting of $\left\{\omega(\lambda_i,\tau_{\tilde{x}})\right\}_{i=1,...,N}$.
  \item $\Lambda(\mathbf{P}) \in \mathbb{R}^{N \times dim(V_h)}$ is a rectangular matrix whose $(i,j)$ entry corresponds to the application of the $i^{th}$ sampling functional applied to the $j^{th}$ basis function.
  \item $\Lambda(\phi) \in \mathbb{R}^N$ is a vector consisting of the $N$ samples of the function $\phi$.
\end{itemize}
We note that by taking the contraction of the tensors appearing in \eqref{discreteTarget} and exploiting the compact support of $\omega$, we may interpret the output of the GMLS process as a finite difference-like stencil of the form 
\begin{equation}
\tau^h_{\tilde{x}}(\phi) = \sum_{\mathbf{x}_i \in B^\epsilon(\tilde{x})} \alpha_i \lambda_i(\phi),
\end{equation}
where $B^\epsilon(\tilde{x})$ denotes the $\epsilon$-ball neighborhood of the target site $\tilde{x}$. Therefore, GMLS admits an interpretation as an automated process for generating generalized finite difference methods on unstructured point clouds. The computational cost of solving the GMLS problem amounts to inverting a small linear system which may be assembled using only information from neighbors within the support of $\omega$, and construction of such stencils across the entire domain is embarrassingly parallel. 

Compadre allows users to control the weighting kernel ($\omega$), degree of the reconstruction basis ($\mathbf{V}_h$), the sampling functionals ($ \left\{\lambda_i(\phi)\right\}_{i=1}^{N}$), and the target operator ($\tau_{\tilde{x}}$); this allows control over smoothness of the reconstruction, locality of the resulting stencil, order of accuracy of the reconstruction (assuming regularity of the function embedded in the point cloud data), choice of what the sampled data or degrees of freedom represent, and linear operator action, respectively.

Selecting point evaluations for sampling functionals and target operator provides a traditional moving least squares reconstruction. As an example of a more exotic choice, it is possible to use an average vector normal integral over edges as the sampling functionals and a cell average integral as the target operator, enabling recovery of functions embedded in a Raviart-Thomas type representation and transferring them to a basis consistent with a finite-volume scheme.

While Compadre supports full space reconstruction in 1-3D, there is also additional support for select sampling functionals and target operators on 1D smooth manifolds embedded in 2D or 2D smooth manifolds embedded in 3D. Reconstruction on a manifold is done through an on-the-fly PCA calculation to determine principal directions tangent to the manifold. The curvature of the manifold is calculated through a reconstruction of the tangent and normal components to the calculated tangent plane, and the final function reconstruction is performed in the local chart. Utilities in the package handle mappings between local computed charts and the ambient higher-dimensional space.

Compadre's stencil generation involves independent problems to be solved in parallel at the team level with loops over the thread and vector level within each problem. This hierarchical parallelism is achieved with performance portability by using the Kokkos programming model and leveraging the batched QR with pivoting algorithm implemented in Kokkos Kernels.
