
@article{Bavier2012a,
  author = {Bavier, Eric and Hoemmen, Mark and Rajamanickam, Sivasankaran and Thornquist, Heidi},
  journal = {Scientific Programming},
  number = {3},
  pages = {241--255},
  title = {{Amesos2 and Belos: Direct and Iterative Solvers for Large Sparse Linear Systems}},
  url = {http://dx.doi.org/10.3233/SPR-2012-0352},
  volume = {20},
  year = {2012}}

@techreport{BergerVergiat2023a,
  address = {Albuquerque, NM (USA) 87185},
  author = {Berger-Vergiat, Luc and Glusa, Christian A. and Harper, Graham and Hu, Jonathan J. and Mayr, Matthias and Prokopenko, Andrey and Siefert, Christopher M. and Tuminaro, Raymond S. and Wiesner, Tobias A.},
  institution = {Sandia National Laboratories},
  number = {SAND2023-12265},
  title = {{MueLu User's Guide}},
  year = {2023}}

@techreport{Gee2006a,
  address = {Albuquerque, NM (USA) 87185},
  author = {Gee, Michael W. and Siefert, Christopher M. and Hu, Jonathan J. and Tuminaro, Ray S. and Sala, Marzio G.},
  institution = {Sandia National Laboratories},
  number = {SAND2006-2649},
  title = {{ML 5.0 Smoothed Aggregation User's Guide}},
  year = {2006}}

@article{Heroux2005a,
  author = {Heroux, Michael A. and Bartlett, Roscoe A. and Howle, Vicki E. and Hoekstra, Robert J. and Hu, Jonathan J. and Kolda, Tamara G. and Lehoucq and Long, Kevin R. and Pawlowski, Roger P. and Phipps, Eric T. and Salinger, Andrew G. and Thornquist, Heidi K. and Tuminaro, Ray S. and Willenbring, James M. and Williams, Alan and Stanley, Kendall S.},
  doi = {10.1145/1089014.1089021},
  journal = {ACM Transactions on Mathematical Software},
  number = {3},
  pages = {397--423},
  title = {{An Overview of the Trilinos Project}},
  volume = {31},
  year = {2005}}

@article{Heroux2012,
author = {Heroux, Michael and Willenbring, James},
year = {2012},
month = {01},
pages = {83-88},
title = {A New Overview of The Trilinos Project},
volume = {20},
journal = {Scientific Programming},
doi = {10.1155/2012/408130}
}

@article{Lin2017a,
  author = {Lin, Paul T. and Shadid, John N. and Hu, Jonathan J. and Pawlowski, Roger P. and Cyr, Eric C.},
  journal = {Journal of Computational and Applied Mathematics},
  pages = {782--793},
  title = {{Performance of fully-coupled algebraic multigrid preconditioners for large-scale VMS resistive MHD}},
  volume = {344},
  year = {2017}}

@article{PyTrilinos, 
 author = {M. Sala and W. Spotz and M. Heroux}, 
 title = {{PyTrilinos}: High-Performance Distributed-Memory Solvers for {Python}},
  journal = {ACM Transactions on Mathematical Software (TOMS)}, 
 year = {2008}, 
 month = {March}, 
 volume = {34}, 
 issue = {2}}

@techreport{Bartlett2010,
  title = {Teuchos C++ memory management classes, idioms, and related topics, the complete reference : a comprehensive strategy for safe and efficient memory management in C++ for high performance computing.},
  author = {Bartlett, Roscoe Ainsworth},
  doi = {10.2172/992335},
  url = {https://www.osti.gov/biblio/992335}, journal = {},
  institution = {Sandia National Laboratories},
  number = {SAND2023-12265},
  place = {United States},
  year = {2010},
  month = {5}
} 

@techreport{Bartlett2014,
  title = {TriBITS Developers Guide and Reference},
  author = {Bartlett, Roscoe A.},
  institution = {Oak Ridge National Laboratory},
  number = {CASL-U-2014-0075-000-b},
  place = {United States},
  year = {2014},
  Month = {3}}

@article{Mayr2022a,
  author = {Mayr, Matthias and Berger-Vergiat, Luc and Ohm, Peter and Tuminaro, Raymond S.},
  doi = {10.1137/20M1375413},
  journal = {SIAM Journal on Scientific Computing},
  number = {4},
  pages = {A2734--A2764},
  title = {Non-invasive multigrid for semi-structured grids},
  url = {https://doi.org/10.1137/20M1375413},
  volume = {44},
  year = {2022}}

@misc{Mayr2023b,
  author = {Mayr, Matthias and Wiesner, Tobias A. and Harper, Graham and Prokopenko, Andrey and Hu, Jonathan J.},
  title = {The MueLu Tutorial},
  howpublished = {https://muelu-tutorial.readthedocs.io/},
  year = {2023}}

@article{Ohm2022a,
  author = {Ohm, Peter and Wiesner, Tobias A. and Cyr, Eric C. and Hu, Jonathan J. and Shadid, John N. and Tuminaro, Raymond S.},
  doi = {10.1553/etna_vol55s365},
  journal = {Electronic Transactions on Numerical Analysis},
  pages = {365--390},
  title = {A Monolithic Algebraic Multigrid Framework for Multiphysics Applications with Examples from Resistive MHD},
  url = {https://doi.org/10.1553/etna_vol55s365},
  volume = {55},
  year = {2022}}

@article{Thomas2019a,
  author = {Thomas, S. J. and Ananthan, S. and Yellapantula, S. and Hu, Jonathan J. and Lawson, M. and Sprague, Michael A.},
  journal = {SIAM Journal on Scientific Computing},
  number = {5},
  pages = {S196--S219},
  title = {A Comparison of Classical and Aggregation-Based Algebraic Multigrid Preconditioners for High-Fidelity Simulations of Wind Turbine Incompressible Flows},
  volume = {41},
  year = {2019}}

@article{Tuminaro2016a,
  author = {Tuminaro, Raymond S. and Perego, Mauro and Tezaur, Irina and Salinger, Andrew G. and Price, S.},
  doi = {10.1137/15M1040839},
  journal = {SIAM Journal on Scientific Computing},
  number = {5},
  pages = {C504--C532},
  title = {{A Matrix Dependent/Algebraic Multigrid Approach for Extruded Meshes with Applications to Ice Sheet Modeling}},
  url = {https://doi.org/10.1137/15M1040839},
  volume = {38},
  year = {2016}}

@article{Vanek1996a,
  author = {Van\v{e}k, Petr and Mandel, Jan and Brezina, Marian},
  journal = {Computing},
  pages = {179--196},
  title = {{Algebraic Multigrid By Smoothed Aggregation For Second And Fourth Order Elliptic Problems}},
  volume = {56},
  year = {1996}}

@article{Wiesner2021a,
  author = {Wiesner, Tobias A. and Mayr, Matthias and Popp, Alexander and Gee, Michael W. and Wall, Wolfgang A.},
  doi = {10.1002/nme.6680},
  journal = {International Journal for Numerical Methods in Engineering},
  number = {15},
  pages = {3749--3779},
  title = {Algebraic multigrid methods for saddle point systems arising from mortar contact formulations},
  url = {https://doi.org/10.1002/nme.6680},
  volume = {122},
  year = {2021}}

@incollection{dohrmann_family_2008,
  series = {Lect. {Notes} {Comput}. {Sci}. {Eng}.},
  title = {A family of energy minimizing coarse spaces for overlapping {Schwarz} preconditioners},
  volume = {60},
  url = {https://mathscinet.ams.org/mathscinet-getitem?mr=2436089},
  urldate = {2022-12-01},
  booktitle = {Domain decomposition methods in science and engineering {XVII}},
  publisher = {Springer, Berlin},
  author = {Dohrmann, Clark R. and Klawonn, Axel and Widlund, Olof B.},
  year = {2008},
  mrnumber = {2436089},
  doi = {10.1007/978-3-540-75199-1_28},
  pages = {247--254}
}

@article{dohrmann_domain_2008,
  title = {Domain decomposition for less regular subdomains: overlapping {Schwarz} in two dimensions},
  volume = {46},
  issn = {0036-1429},
  shorttitle = {Domain decomposition for less regular subdomains},
  url = {https://mathscinet.ams.org/mathscinet-getitem?mr=2399412},
  doi = {10.1137/070685841},
  number = {4},
  urldate = {2022-12-01},
  journal = {SIAM Journal on Numerical Analysis},
  author = {Dohrmann, Clark R. and Klawonn, Axel and Widlund, Olof B.},
  year = {2008},
  mrnumber = {2399412},
  pages = {2153--2168}
}

@article{heinlein_parallel_2016,
  title = {A parallel implementation of a two-level overlapping {Schwarz} method with energy-minimizing coarse space based on {Trilinos}},
  volume = {38},
  issn = {1064-8275},
  url = {https://mathscinet.ams.org/mathscinet-getitem?mr=3579700},
  doi = {10.1137/16M1062843},
  number = {6},
  urldate = {2022-12-01},
  journal = {SIAM Journal on Scientific Computing},
  author = {Heinlein, Alexander and Klawonn, Axel and Rheinbach, Oliver},
  year = {2016},
  mrnumber = {3579700},
  keywords = {65F08, 65F10, domain decomposition, GDSW, overlapping Schwarz, 65M55, 65Y05, fluid-structure interaction, parallel, scientific software},
  pages = {C713--C747}
}


@inproceedings{heinlein_improving_2018,
	series = {Lect. {Notes} {Comput}. {Sci}. {Eng}.},
	title = {Improving the parallel performance of overlapping {Schwarz} methods by using a smaller energy minimizing coarse space},
	volume = {125},
	url = {https://mathscinet.ams.org/mathscinet-getitem?mr=3989887},
	doi = {10.1007/978-3-319-93873-8_3},
	urldate = {2022-12-01},
	booktitle = {Domain decomposition methods in science and engineering {XXIV}},
	publisher = {Springer, Cham},
	author = {Heinlein, Alexander and Klawonn, Axel and Rheinbach, Oliver and Widlund, Olof B.},
	year = {2018},
	mrnumber = {3989887},
	pages = {383--392}
}


@incollection{heinlein_frosch_2020,
  series = {Lect. {Notes} {Comput}. {Sci}. {Eng}.},
  title = {{FROSch}: a fast and robust overlapping {Schwarz} domain decomposition preconditioner based on {Xpetra} in {Trilinos}},
  volume = {138},
  shorttitle = {{FROSch}},
  url = {https://mathscinet.ams.org/mathscinet-getitem?mr=4167553},
  urldate = {2023-02-09},
  booktitle = {Domain decomposition methods in science and engineering {XXV}},
  publisher = {Springer, Cham},
  author = {Heinlein, Alexander and Klawonn, Axel and Rajamanickam, Sivasankaran and Rheinbach, Oliver},
  year = {2020},
  mrnumber = {4167553},
  doi = {10.1007/978-3-030-56750-7_19},
  pages = {176--184}
}


@article{heinlein_monolithic_2019,
  title = {Monolithic overlapping {Schwarz} domain decomposition methods with {GDSW} coarse spaces for incompressible fluid flow problems},
  volume = {41},
  issn = {1064-8275},
  url = {https://mathscinet.ams.org/mathscinet-getitem?mr=3976649},
  doi = {10.1137/18M1184047},
  number = {4},
  urldate = {2022-12-01},
  journal = {SIAM Journal on Scientific Computing},
  author = {Heinlein, Alexander and Hochmuth, Christian and Klawonn, Axel},
  year = {2019},
  mrnumber = {3976649},
  keywords = {65F08, 65F10, domain decomposition, GDSW, 65M55, 65Y05, parallel computing, algebraic preconditioner, Stokes, monolithic overlapping Schwarz, Navier--Stokes, saddle point problems},
  pages = {C291--C316}
}


@article{heinlein_frosch_2022,
  title = {{FROSch} preconditioners for land ice simulations of {Greenland} and {Antarctica}},
  volume = {44},
  issn = {1064-8275},
  url = {https://mathscinet.ams.org/mathscinet-getitem?mr=4399027},
  doi = {10.1137/21M1395260},
  number = {2},
  urldate = {2022-12-01},
  journal = {SIAM Journal on Scientific Computing},
  author = {Heinlein, Alexander and Perego, Mauro and Rajamanickam, Sivasankaran},
  year = {2022},
  mrnumber = {4399027},
  keywords = {65F08, 65N55, 65M55, 65Y05, domain decomposition methods, GDSW coarse spaces, monolithic Schwarz preconditioners, multiphysics simulations, parallel computing},
  pages = {B339--B367}
}

@article{heinlein_parallel_2022,
  title = {Parallel {Scalability} of {Three}-{Level} {FROSch} {Preconditioners} to 220000 {Cores} using the {Theta} {Supercomputer}},
  issn = {1064-8275},
  url = {https://epubs-siam-org.tudelft.idm.oclc.org/doi/10.1137/21M1431205},
  doi = {10.1137/21M1431205},
  abstract = {The parallel performance of the three-level fast and robust overlapping Schwarz (FROSch) preconditioners is investigated for linear elasticity. The FROSch framework is part of the Trilinos software library and contains a parallel implementation of different preconditioners with energy minimizing coarse spaces of generalized Dryja--Smith--Widlund type. The three-level extension is constructed by a recursive application of the FROSch preconditioner to the coarse problem. In this paper, the additional steps in the implementation in order to apply the FROSch preconditioner recursively are described in detail. Furthermore, it is shown that no explicit geometric information is needed in the recursive application of the preconditioner. In particular, the rigid body modes, including the rotations, can be interpolated on the coarse level without additional geometric information. Parallel results for a three-dimensional linear elasticity problem obtained on the Theta supercomputer (Argonne Leadership Computing Facility, Argonne, IL) using up to 220 000 cores are discussed and compared to results obtained on the SuperMUC-NG supercomputer (Leibniz Supercomputing Centre, Garching, Germany). Notably, it can be observed that a hierarchical communication operation in FROSch related to the coarse operator starts to dominate the computing time on Theta, which has a dragonfly interconnect, for 100 000 message passing interface (MPI) ranks or more. The same operation, however, scales well and stays within the order of a second in all experiments performed on SuperMUC-NG, which uses a fat tree network. Using hybrid MPI/OpenMP parallelization, the onset of the MPI communication problem on Theta can be delayed. Further analysis of the performance of FROSch on large supercomputers with dragonfly interconnects will be necessary.},
  urldate = {2022-12-17},
  journal = {SIAM Journal on Scientific Computing},
  author = {Heinlein, Alexander and Rheinbach, Oliver and Röver, Friederike},
  month = aug,
  year = {2022},
  note = {Publisher: Society for Industrial and Applied Mathematics},
  keywords = {65N55, domain decomposition, overlapping Schwarz, 74B05, high performance computing, multilevel preconditioners, software, Trilinos},
  pages = {S173--S198}
}

@techreport{Yamazaki:2022:EST,
  author = {Yamazaki, Ichitaro and Heinlein, Alexander and Rajamanickam, Sivasankaran},
  title = {An Experimental Study of Two-level Schwarz Domain-Decomposition Preconditioners on GPUs},
  note = {Accepted for publication in the IPDPS’23 proceedings. December 2022}
}

@article{heinlein_adaptive_2019,
  title = {Adaptive {GDSW} coarse spaces for overlapping {Schwarz} methods in three dimensions},
  volume = {41},
  issn = {1064-8275},
  url = {https://mathscinet.ams.org/mathscinet-getitem?mr=4014789},
  doi = {10.1137/18M1220613},
  number = {5},
  urldate = {2022-12-01},
  journal = {SIAM Journal on Scientific Computing},
  author = {Heinlein, Alexander and Klawonn, Axel and Knepper, Jascha and Rheinbach, Oliver},
  year = {2019},
  mrnumber = {4014789},
  keywords = {65F08, 65F10, 65N55, 68W10, adaptive coarse spaces, domain decomposition, GDSW, multiscale, overlapping Schwarz},
  pages = {A3045--A3072}
}

@misc{frosch_demo,
  title = {{FROSch} Demo},
  howpublished = {\url{https://github.com/searhein/frosch-demo}},
  note = {Accessed: 2023-04-05}
}

@misc{osti_1231283,
title = {Piro v. 1.0, Version 00},
author = {Salinger, Andrew and Phipps, Eric T},
doi = {},
url = {https://www.osti.gov/biblio/1231283},
year = {2010},
month = {2},
}

@misc{phipps2015stokhos,
  title={Stokhos stochastic Galerkin uncertainty quantification methods},
  author={Phipps, Eric T},
  year={2015}
}

@article{phipps2017embedded,
  title={Embedded ensemble propagation for improving performance, portability, and scalability of uncertainty quantification on emerging computational architectures},
  author={Phipps, Eric T and D'Elia, Marta and Edwards, H Carter and Hoemmen, Mark and Hu, Jonathan and Rajamanickam, Sivasankaran},
  journal={SIAM Journal on Scientific Computing},
  volume={39},
  number={2},
  pages={C162--C193},
  year={2017},
  publisher={SIAM}
}

@article{pawlowski2012automating,
  title={Automating embedded analysis capabilities and managing software complexity in multiphysics simulation, Part I: Template-based generic programming},
  author={Pawlowski, Roger P and Phipps, Eric T and Salinger, Andrew G},
  journal={Scientific Programming},
  volume={20},
  number={2},
  pages={197--219},
  year={2012},
  publisher={IOS Press}
}

@article{ghanem1990polynomial,
  title={Polynomial chaos in stochastic finite elements},
  author={Ghanem, Roger and Spanos, Pol D},
  year={1990}
}

@book{ghanem2003stochastic,
  title={Stochastic finite elements: a spectral approach},
  author={Ghanem, Roger G and Spanos, Pol D},
  year={2003},
  publisher={Courier Corporation}
}


@article{liegeois2020gmres,
  title={GMRES with embedded ensemble propagation for the efficient solution of parametric linear systems in uncertainty quantification of computational models},
  author={Liegeois, Kim and Boman, Romain and Phipps, Eric T and Wiesner, Tobias A and Arnst, Maarten},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={369},
  pages={113188},
  year={2020},
  publisher={Elsevier}
}

@article{phipps2022automatic,
  title={Automatic Differentiation of C++ Codes on Emerging Manycore Architectures with Sacado},
  author={Phipps, Eric and Pawlowski, Roger and Trott, Christian},
  journal={ACM Transactions on Mathematical Software},
  volume={48},
  number={4},
  pages={1--29},
  year={2022},
  publisher={ACM New York, NY}
}

@incollection{phipps2012efficient,
  title={Efficient expression templates for operator overloading-based automatic differentiation},
  author={Phipps, Eric and Pawlowski, Roger},
  booktitle={Recent Advances in Algorithmic Differentiation},
  pages={309--319},
  year={2012},
  publisher={Springer}
}

@article{phipps2008large,
  title={Large-scale transient sensitivity analysis of a radiation-damaged bipolar junction transistor via automatic differentiation},
  author={Phipps, Eric T and Bartlett, Roscoe A and Gay, David M and Hoekstra, Robert J},
  journal={Advances in automatic differentiation},
  volume={64},
  pages={351--362},
  year={2008},
  publisher={Springer}
}


@misc{SacadoURL,
  author = {E. T. Phipps and D. M. Gay},
  howpublished = {\url{http://trilinos.sandia.gov/packages/sacado/}},
  title = {{Sacado Automatic Differentiation Package}},
  year = {2011}
}

@article{Salinger2016,
  author  = {Andrew G. Salinger and Roscoe A.  Bartlett and Andrew M.  Bradley and Qiushi  Chen and Irina P.  Demeshko and Xujiao  Gao and Glen A. Hansen and Alejandro  Mota and Richard P.  Muller and Erik  Nielsen and Jakob T.  Ostien and Roger P.  Pawlowski and Mauro Perego and Eric T. Phipps and WaiChing Sun and Irina K.  Tezaur},
  title   = {ALBANY: USING COMPONENT-BASED DESIGN TO DEVELOP A FLEXIBLE, GENERIC MULTIPHYSICS ANALYSIS CODE},
  journal = {International Journal for Multiscale Computational Engineering},
  issn    = {1543-1649},
  year    = {2016},
  volume  = {14},
  number  = {4},
  pages   = {415--438}
}

@Article{MPASAlbany2018,
AUTHOR = {Hoffman, M. J. and Perego, M. and Price, S. F. and Lipscomb, W. H. and Zhang, T. and Jacobsen, D. and Tezaur, I. and Salinger, A. G. and Tuminaro, R. and Bertagna, L.},
TITLE = {MPAS-Albany Land Ice (MALI): a variable-resolution ice sheet model for Earth system modeling using Voronoi grids},
JOURNAL = {Geoscientific Model Development},
VOLUME = {11},
YEAR = {2018},
NUMBER = {9},
PAGES = {3747--3780},
URL = {https://www.geosci-model-dev.net/11/3747/2018/},
DOI = {10.5194/gmd-11-3747-2018}
}

@TechReport{CharonUsersManual2020,
  author =    {Lawrence C. Musson and Gary L. Hennigan and Xujiao Gao and Richard Humphries and Mihai Negoita and Andy Huang},
  title =    {{Charon Users Manual: v. 2.1 (revision1)}},
  institution =  {Sandia National Laboratories},
  year =    {2020},
  number =    {{SAND2020-5266}}
}

@inproceedings{Musson2009,
author = {Lawrence C. Musson and Roger P. Pawlowski and Andrew G. Salinger and Timothy J. Madden and Kevin B. Hewett},
title = {{Multiphase reacting flow modeling of singlet oxygen generators for chemical oxygen iodine lasers}},
volume = {7131},
booktitle = {XVII International Symposium on Gas Flow, Chemical Lasers, and High-Power Lasers},
editor = {Rui Vilar and Olinda Conde and Marta Fajardo and Luís O. Silva and Margarida Pires and Andrei Utkin},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {148 -- 155},
keywords = {Singlet Oxygen generator, chemical oxygen iodine laser, sog, coil},
year = {2009},
doi = {10.1117/12.816415},
URL = {https://doi.org/10.1117/12.816415}
}

@article{Sondak2021,
title = {High Rayleigh number variational multiscale large eddy simulations of Rayleigh-Bénard convection},
journal = {Mechanics Research Communications},
volume = {112},
pages = {103614},
year = {2021},
note = {Special issue honoring G.I. Taylor Medalist Prof. Arif Masud},
issn = {0093-6413},
doi = {https://doi.org/10.1016/j.mechrescom.2020.103614},
url = {https://www.sciencedirect.com/science/article/pii/S0093641320301427},
author = {David Sondak and Thomas M. Smith and Roger P. Pawlowski and Sidafa Conde and John N. Shadid},
keywords = {Rayleigh-Bénard convection, Large eddy simulation, Variational multiscale formulation},
abstract = {The variational multiscale (VMS) formulation is used to develop residual-based VMS large eddy simulation (LES) models for Rayleigh-Bénard convection. The resulting model is a mixed model that incorporates the VMS model and an eddy viscosity model. The Wall-Adapting Local Eddy-viscosity (WALE) model is used as the eddy viscosity model in this work. The new LES models were implemented in the finite element code Drekar. Simulations are performed using continuous, piecewise linear finite elements. The simulations ranged from Ra=106 to Ra=1014 and were conducted at Pr=1 and Pr=7. Two domains were considered: a two-dimensional domain of aspect ratio 2 with a fluid confined between two parallel plates and a three-dimensional cylinder of aspect ratio 1/4. The Nusselt number from the VMS results is compared against three dimensional direct numerical simulations and experiments. In all cases, the VMS results are in good agreement with existing literature.}
}

@article{Shadid2016,
title = {Stabilized FE simulation of prototype thermal-hydraulics problems with integrated adjoint-based capabilities},
journal = {Journal of Computational Physics},
volume = {321},
pages = {321-341},
year = {2016},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2016.04.062},
url = {https://www.sciencedirect.com/science/article/pii/S0021999116301280},
author = {J.N. Shadid and T.M. Smith and E.C. Cyr and T.M. Wildey and R.P. Pawlowski},
keywords = {Reynolds averaged Navier–Stokes, Stabilized finite elements, Adjoints, Sensitivities, Error-estimation, Uncertainty quantification},
abstract = {A critical aspect of applying modern computational solution methods to complex multiphysics systems of relevance to nuclear reactor modeling, is the assessment of the predictive capability of specific proposed mathematical models. In this respect the understanding of numerical error, the sensitivity of the solution to parameters associated with input data, boundary condition uncertainty, and mathematical models is critical. Additionally, the ability to evaluate and or approximate the model efficiently, to allow development of a reasonable level of statistical diagnostics of the mathematical model and the physical system, is of central importance. In this study we report on initial efforts to apply integrated adjoint-based computational analysis and automatic differentiation tools to begin to address these issues. The study is carried out in the context of a Reynolds averaged Navier–Stokes approximation to turbulent fluid flow and heat transfer using a particular spatial discretization based on implicit fully-coupled stabilized FE methods. Initial results are presented that show the promise of these computational techniques in the context of nuclear reactor relevant prototype thermal-hydraulics problems.}
}

@article{SHADID2016mhd,
title = "Scalable implicit incompressible resistive MHD with stabilized FE and fully-coupled Newton-Krylov-AMG",
journal = "Computer Methods in Applied Mechanics and Engineering",
volume = "304",
pages = "1 - 25",
year = "2016",
issn = "0045-7825",
doi = "https://doi.org/10.1016/j.cma.2016.01.019",
url = "http://www.sciencedirect.com/science/article/pii/S0045782516300184",
author = "J.N. Shadid and R.P. Pawlowski and E.C. Cyr and R.S. Tuminaro and L. Chacon and P.D. Weber",
keywords = "Stabilized FE, Variational multiscale methods, Resistive magnetohydrodynamics, Implicit methods, Newton–Krylov, Algebraic multigrid methods",
abstract = "The computational solution of the governing balance equations for mass, momentum, heat transfer and magnetic induction for resistive magnetohydrodynamics (MHD) systems can be extremely challenging. These difficulties arise from both the strong nonlinear, nonsymmetric coupling of fluid and electromagnetic phenomena, as well as the significant range of time- and length-scales that the interactions of these physical mechanisms produce. This paper explores the development of a scalable, fully-implicit stabilized unstructured finite element (FE) capability for 3D incompressible resistive MHD. The discussion considers the development of a stabilized FE formulation in context of the variational multiscale (VMS) method, and describes the scalable implicit time integration and direct-to-steady-state solution capability. The nonlinear solver strategy employs Newton–Krylov methods, which are preconditioned using fully-coupled algebraic multilevel preconditioners. These preconditioners are shown to enable a robust, scalable and efficient solution approach for the large-scale sparse linear systems generated by the Newton linearization. Verification results demonstrate the expected order-of-accuracy for the stabilized FE discretization. The approach is tested on a variety of prototype problems, that include MHD duct flows, an unstable hydromagnetic Kelvin–Helmholtz shear layer, and a 3D island coalescence problem used to model magnetic reconnection. Initial results that explore the scaling of the solution methods are also presented on up to 128K processors for problems with up to 1.8B unknowns on a CrayXK7."
}

@article{Crockatt2022,
title = {An implicit monolithic AFC stabilization method for the CG finite element discretization of the fully-ionized ideal multifluid electromagnetic plasma system},
journal = {Journal of Computational Physics},
volume = {464},
pages = {111228},
year = {2022},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2022.111228},
url = {https://www.sciencedirect.com/science/article/pii/S002199912200290X},
author = {Michael M. Crockatt and Sibusiso Mabuza and John N. Shadid and Sidafa Conde and Thomas M. Smith and Roger P. Pawlowski},
keywords = {Linearity preservation, Continuous Galerkin method, Iterative limiters, Artificial diffusion, Multifluid plasma, Algebraic flux correction},
abstract = {This study considers an implicit finite element formulation for an ideal fully-ionized multifluid electromagnetic plasma system. The formulation is based on fully-implicit Runge-Kutta time discretizations and a monolithic discrete algebraic flux corrected (AFC) continuous Galerkin (CG) spatial discretization of the coupled system. The AFC approach adds scalar artificial diffusion to the high-order, semi-discrete Galerkin method and uses mass lumping in the time derivative term. The result is a low-order method that attempts to enforce local-extremum-diminishing properties for the hyperbolic system. An element-based iterative limiter is applied to reduce the amount of artificial diffusion that is used in regions where the solution is smooth and the additional stabilization is not required. Two models are considered for the electromagnetics portion of the system: an electrostatic model, and a full Maxwell system with a parabolic divergence cleaning approach that enforces the required involutions on the electric and magnetic fields. Results are presented that demonstrate the accuracy and robustness of the formulation for smooth and discontinuous solutions to challenging plasma physics problems. This includes a demonstration that the solution of the full multifluid system yields the expected behavior in the ideal shock-MHD limit.}
}

@article{Miller2019,
title = {IMEX and exact sequence discretization of the multi-fluid plasma model},
journal = {Journal of Computational Physics},
volume = {397},
pages = {108806},
year = {2019},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2019.05.052},
url = {https://www.sciencedirect.com/science/article/pii/S0021999119304905},
author = {S.T. Miller and E.C. Cyr and J.N. Shadid and R.M.J. Kramer and E.G. Phillips and S. Conde and R.P. Pawlowski},
keywords = {Multi-fluid plasmas, Exact sequence discretizations, IMEX, Finite element methods},
abstract = {Multi-fluid plasma models, where an electron fluid is modeled in addition to multiple ion and neutral species as well as the full set of Maxwell's equations, are useful for representing physics beyond the scope of classic MHD. This advantage presents challenges in appropriately dealing with electron dynamics and electromagnetic behavior characterized by the plasma and cyclotron frequencies and the speed of light. For physical systems, such as those near the MHD asymptotic regime, this requirement drastically increases runtimes for explicit time integration even though resolving fast dynamics may not be critical for accuracy. Implicit time integration methods, with efficient solvers, can help to step over fast time-scales that constrain stability, but do not strongly influence accuracy. As an extension, Implicit-explicit (IMEX) schemes provide an additional mechanism to choose which dynamics are evolved using an expensive implicit solve or resolved using a fast explicit solve. In this study, in addition to IMEX methods we also consider a physics compatible exact sequence spatial discretization. This combines nodal bases (H-Grad) for fluid dynamics with a set of vector bases (H-Curl and H-Div) for Maxwell's equations. This discretization allows for multi-fluid plasma modeling without violating Gauss' laws for the electric and magnetic fields. This initial study presents a discussion of the major elements of this formulation and focuses on demonstrating accuracy in the linear wave regime and in the MHD limit for both a visco-resistive and a dispersive ideal MHD problem.}
}

@InProceedings{xyceTrilinos,
author="Baker, Chris
and Boman, Erik
and Heroux, Mike
and Keiter, Eric
and Rajamanickam, Siva
and Schiek, Rich
and Thornquist, Heidi",
editor="Alexander, Michael
and D'Ambra, Pasqua
and Belloum, Adam
and Bosilca, George
and Cannataro, Mario
and Danelutto, Marco
and Di Martino, Beniamino
and Gerndt, Michael
and Jeannot, Emmanuel
and Namyst, Raymond
and Roman, Jean
and Scott, Stephen L.
and Traff, Jesper Larsson
and Vall{\'e}e, Geoffroy
and Weidendorfer, Josef",
title="Enabling Next-Generation Parallel Circuit Simulation with Trilinos",
booktitle="Euro-Par 2011: Parallel Processing Workshops",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="315--323",
abstract="The Xyce Parallel Circuit Simulator, which has demonstrated scalable circuit simulation on hundreds of processors, heavily leverages the high-performance scientific libraries provided by Trilinos. With the move towards multi-core CPUs and GPU technology, retaining this scalability on future parallel architectures will be a challenge. This paper will discuss how Trilinos is an enabling technology that will optimize the trade-off between effort and impact for application codes, like Xyce, in their transition to becoming next-generation simulation tools.",
isbn="978-3-642-29737-3",
doi={10.1007/978-3-642-29737-3_36}
}

@InProceedings{xycePCE,
author="Keiter, Eric R.
and Swiler, Laura P.
and Wilcox, Ian Z.",
editor="Langer, Ulrich
and Amrhein, Wolfgang
and Zulehner, Walter",
title="Gradient-Enhanced Polynomial Chaos Methods for Circuit Simulation",
booktitle="Scientific Computing in Electrical Engineering",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="55--68",
abstract="Uncertainty Quantification (UQ) is an important and emerging topic in electronic design automation (EDA), as parametric uncertainties are a significant concern for the design of integrated circuits. Historically, various sampling methods such as Monte Carlo (MC) and Latin Hypercube Sampling (LHS) have been employed, but these methods can be prohibitively expensive. Polynomial Chaos Expansion (PCE) methods are often proposed as an alternative to sampling. PCE methods have a number of variations, representing tradeoffs. Regression-based PCE methods, for example, can be applied to existing sample sets and don't require specific quadrature points. However, this comes at the cost of accuracy. In this paper we explore the idea of enhancing regression-based PCE methods using gradient information. The gradient information is provided by an intrusive adjoint sensitivity algorithm embedded in the circuit simulator.",
isbn="978-3-319-75538-0",
doi="10.1007/978-3-319-75538-0\_6"
}

@inbook{SparcValidation,
author = {Sarah L. Kieweg and Jaideep Ray and V. G. Weirs and Brian Carnes and Derek Dinzl and Brian Freno and Micah Howard and Eric Phipps and William Rider and Thomas Smith},
title = {Validation Assessment of Hypersonic Double-Cone Flow Simulations using Uncertainty Quantification, Sensitivity Analysis, and Validation Metrics},
booktitle = {AIAA Scitech 2019 Forum},
chapter = {},
pages = {},
doi = {10.2514/6.2019-2278},
xURL = {https://arc.aiaa.org/doi/abs/10.2514/6.2019-2278},
xeprint = {https://arc.aiaa.org/doi/pdf/10.2514/6.2019-2278}
}


@inbook{Phipps2016,
  abstract = {Stokhos (Phipps, Stokhos embedded uncertainty quantification methods. http://trilinos.org/packages/stokhos/, 2015) is a package within Trilinos (Heroux et al., ACM Trans Math Softw 31(3), 2005; Michael et al., Sci Program 20(2):83--88, 2012) that enables embedded or intrusive uncertainty quantification capabilities to C++ codes. It provides tools for implementing stochastic Galerkin methodsStochastic Galerkin methodsand embedded sample propagation through the use of template-based generic programming (Pawlowski et al., Sci Program 20:197--219, 2012; Roger et al., Sci Program 20:327--345, 2012) which allows deterministic simulation codes to be easily modified for embedded uncertainty quantification. It provides tools for forming and solving the resulting linear and nonlinear equations these methods generate, leveraging the large-scale linear and nonlinear solver capabilities provided by Trilinos. Furthermore, Stokhos is integrated with the emerging many-core architecture capabilities provided by the Kokkos (Edwards et al., Sci Program 20(2):89--114, 2012; Edwards et al., J Parallel Distrib Comput 74(12):3202--3216, 2014) and Tpetra packages (Baker and Heroux, Sci Program 20(2):115--128, 2012; Hoemmen et al., Tpetra: next-generation distributed linear algebra. http://trilinos.org/packages/tpetra, 2015) within Trilinos, allowing these embedded uncertainty quantification capabilities to be applied in both shared and distributed memory parallel computational environments. Finally, the Stokhos tools have been incorporated into the Albany simulation code (Pawlowski et al., Sci Program 20:327--345, 2012; Salinger et al., Albany multiphysics simulation code. https://github.com/gahansen/Albany, 2015) enabling embedded uncertainty quantification of a wide variety of large-scale PDE-based simulations.},
  address = {Cham},
  author = {Phipps, Eric T. and Salinger, Andrew G.},
  booktitle = {Handbook of Uncertainty Quantification},
  doi = {10.1007/978-3-319-11259-6_55-1},
  editor = {Ghanem, Roger and Higdon, David and Owhadi, Houman},
  isbn = {978-3-319-11259-6},
  pages = {1--43},
  publisher = {Springer International Publishing},
  title = {Embedded Uncertainty Quantification Methods via Stokhos},
  url = {https://doi.org/10.1007/978-3-319-11259-6_55-1},
  year = {2016},
  Bdsk-Url-1 = {https://doi.org/10.1007/978-3-319-11259-6_55-1}
}

@article{phipps2014exploring,
  title={Exploring emerging manycore architectures for uncertainty quantification through embedded stochastic Galerkin methods},
  author={Phipps, Eric and Edwards, H Carter and Hu, Jonathan and Ostien, Jakob T},
  journal={International Journal of Computer Mathematics},
  volume={91},
  number={4},
  pages={707--729},
  year={2014},
  publisher={Taylor \& Francis}
}

@article{constantine2014efficient,
  title={Efficient uncertainty propagation for network multiphysics systems},
  author={Constantine, Paul G and Phipps, Eric T and Wildey, Timothy M},
  journal={International Journal for Numerical Methods in Engineering},
  volume={99},
  number={3},
  pages={183--202},
  year={2014},
  publisher={Wiley Online Library}
}

@article{trott2021kokkos,
  title={The Kokkos ecosystem: Comprehensive performance portability for high performance computing},
  author={Trott, Christian and Berger-Vergiat, Luc and Poliakoff, David and Rajamanickam, Sivasankaran and Lebrun-Grandie, Damien and Madsen, Jonathan and Al Awar, Nader and Gligoric, Milos and Shipman, Galen and Womeldorff, Geoff},
  journal={Computing in Science \& Engineering},
  volume={23},
  number={5},
  pages={10--18},
  year={2021},
  publisher={IEEE}
}

@article{rajamanickam2021kokkoskernels,
  title={Kokkos kernels: Performance portable sparse/dense linear algebra and graph kernels},
  author={Rajamanickam, Sivasankaran and Acer, Seher and Berger-Vergiat, Luc and Dang, Vinh and Ellingwood, Nathan and Harvey, Evan and Kelley, Brian and Trott, Christian R and Wilke, Jeremiah and Yamazaki, Ichitaro},
  journal={arXiv preprint arXiv:2103.11991},
  year={2021},
  pages={1--12},
  number={-},
  volume={-}
}

@article{liegeois2023performance,
  title={Performance Portable Batched Sparse Linear Solvers},
  author={Liegeois, Kim and Rajamanickam, Sivasankaran and Berger-Vergiat, Luc},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={34},
  number={5},
  pages={1524--1535},
  year={2023},
  publisher={IEEE}
}

@inproceedings{kelley2022parallel,
  title={Parallel, Portable Algorithms for Distance-2 Maximal Independent Set and Graph Coarsening},
  author={Kelley, Brian and Rajamanickam, Sivasankaran},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  pages={280--290},
  year={2022},
  organization={IEEE},
  publisher = {IEEE Computer Society},
  address = {Los Alamitos, CA, USA}
}

@inproceedings{kim2017designing,
  title={Designing vector-friendly compact BLAS and LAPACK kernels},
  author={Kim, Kyungjoo and Costa, Timothy B and Deveci, Mehmet and Bradley, Andrew M and Hammond, Simon D and Guney, Murat E and Knepper, Sarah and Story, Shane and Rajamanickam, Sivasankaran},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--12},
  year={2017},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA}
}

@article{deveci2018multithreaded,
  title={Multithreaded sparse matrix-matrix multiplication for many-core and GPU architectures},
  author={Deveci, Mehmet and Trott, Christian and Rajamanickam, Sivasankaran},
  journal={Parallel Computing},
  volume={78},
  pages={33--46},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{wolf2017fast,
  title={Fast linear algebra-based triangle counting with kokkoskernels},
  author={Wolf, Michael M and Deveci, Mehmet and Berry, Jonathan W and Hammond, Simon D and Rajamanickam, Sivasankaran},
  booktitle={2017 IEEE High Performance Extreme Computing Conference (HPEC)},
  pages={1--7},
  year={2017},
  publisher={IEEE},
  address = {Los Alamitos, CA, USA}
}


@inproceedings{hoemmen2015tpetra,
title = {Tpetra Project Overview},
author = {Hoemmen, Mark Frederick},
url = {https://www.osti.gov/biblio/1307283},
booktitle={{HPCOR} Workshop},
place = {United States},
year = {2015},
month = {9}
}


@article{Vanka1986,
  title   = {Block-implicit multigrid solution of {N}avier-{S}tokes equations in primitive variables},
  author  = {Vanka, S Pratap},
  journal = {Journal of Computational Physics},
  year    = {1986},
  number  = {1},
  pages   = {138--158},
  volume  = {65},
}


@article{Hiptmair1997,
  author   = {Hiptmair, Ralf},
  title    = {Multigrid method for {H}(div) in three dimensions},
  journal  = {Electron. Trans. Numer. Anal},
  year     = {1997},
  volume   = {6},
  pages    = {133--152},
  }

@Article{BochevHuEtAl2008_AlgebraicMultigridApproachBased,
  author =       {Bochev, Pavel B and Hu, Jonathan J and Siefert,
                  Christopher M and Tuminaro, Raymond S},
  title =        {An algebraic multigrid approach based on a
                  compatible gauge reformulation of Maxwell's
                  equations},
  journal =      {SIAM Journal on Scientific Computing},
  year =         2008,
  volume =       31,
  number =       1,
  pages =        {557--583},
  publisher =    {SIAM},
}

@Article{BettencourtBrownEtAl2021_EmpirePic,
  author =       {Bettencourt, {Matthew T.} and Brown, {Dominic A. S.}
                  and Cartwright, {Keith L.} and Cyr, {Eric C.} and
                  Glusa, {Christian A.} and Lin, {Paul T.} and Moore,
                  {Stan G.} and McGregor, {Duncan A. O.} and Roger
                  Pawlowski and Phillips, {Edward G.} and Roberts,
                  {Nathan V.} and Wright, {Steven A.} and Satheesh
                  Maheswaran and Jones, {John P.} and Stephen Jarvis},
  title =        {EMPIRE-PIC: A Performance Portable Unstructured
                  Particle-in-Cell Code},
  journal =      {Communications in Computational Physics},
  year =         2021,
  volume =       30,
  number =       4,
  pages =        {1232--1268},
  month =        aug,
  doi =          {10.4208/cicp.OA-2020-0261},
  language =     {English},
  issn =         {1815-2406},
  publisher =    {Global Science Press},
}

@Article{CyrShadidEtAl2012_StabilizationScalableBlockPreconditioning,
  author =       {Eric C. Cyr and John N. Shadid and Raymond S.
                  Tuminaro},
  title =        {Stabilization and scalable block preconditioning for
                  the Navier–Stokes equations},
  journal =      {Journal of Computational Physics},
  year =         2012,
  volume =       231,
  number =       2,
  pages =        {345-363},
  issn =         {0021-9991},
  doi =          {https://doi.org/10.1016/j.jcp.2011.09.001},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0021999111005195},
}

@techreport{Heroux2004a,
  address = {Albuquerque, NM (USA) 87185},
  author = {Heroux, M. A.},
  institution = {Sandia National Laboratories},
  number = {SAND2004-3796},
  title = {{AztecOO User Guide}},
  year = {2004}
}

@article{GHYSELS2014224,
title = {Hiding global synchronization latency in the preconditioned Conjugate Gradient algorithm},
journal = {Parallel Computing},
volume = {40},
number = {7},
pages = {224-238},
year = {2014},
note = {7th Workshop on Parallel Matrix Algorithms and Applications},
issn = {0167-8191},
doi = {https://doi.org/10.1016/j.parco.2013.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167819113000719},
author = {P. Ghysels and W. Vanroose},
keywords = {Conjugate gradients, Parallelization, Global communication, Latency hiding, Conjugate residuals},
abstract = {Scalability of Krylov subspace methods suffers from costly global synchronization steps that arise in dot-products and norm calculations on parallel machines. In this work, a modified preconditioned Conjugate Gradient (CG) method is presented that removes the costly global synchronization steps from the standard CG algorithm by only performing a single non-blocking reduction per iteration. This global communication phase can be overlapped by the matrix-vector product, which typically only requires local communication. The resulting algorithm will be referred to as pipelined CG. An alternative pipelined method, mathematically equivalent to the Conjugate Residual (CR) method that makes different trade-offs with regard to scalability and serial runtime is also considered. These methods are compared to a recently proposed asynchronous CG algorithm by Gropp. Extensive numerical experiments demonstrate the numerical stability of the methods. Moreover, it is shown that hiding the global synchronization step improves scalability on distributed memory machines using the message passing paradigm and leads to significant speedups compared to standard preconditioned CG.
}
}

@article{Saad1993a,
author = {Saad, Youcef},
title = {A Flexible Inner-Outer Preconditioned GMRES Algorithm},
journal = {SIAM Journal on Scientific Computing},
volume = {14},
number = {2},
pages = {461-469},
year = {1993},
doi = {10.1137/0914028}
}

@article{Parker2012SamplingGD,
  title={Sampling Gaussian Distributions in Krylov Spaces with Conjugate Gradients},
  author={Albert E. Parker and Colin Fox},
  journal={SIAM J. Sci. Comput.},
  year={2012},
  volume={34}
}

@article{Baker2009a,
author = {Baker, C. G. and Hetmaniuk, U. L. and Lehoucq, R. B. and Thornquist, H. K.},
title = {Anasazi Software for the Numerical Solution of Large-Scale Eigenvalue Problems},
year = {2009},
issue_date = {July 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {3},
issn = {0098-3500},
url = {https://doi.org/10.1145/1527286.1527287},
doi = {10.1145/1527286.1527287},
abstract = {Anasazi is a package within the Trilinos software project that provides a framework for the iterative, numerical solution of large-scale eigenvalue problems. Anasazi is written in ANSI C++ and exploits modern software paradigms to enable the research and development of eigensolver algorithms. Furthermore, Anasazi provides implementations for some of the most recent eigensolver methods. The purpose of our article is to describe the design and development of the Anasazi framework. A performance comparison of Anasazi and the popular FORTRAN 77 code ARPACK is given.},
journal = {ACM Trans. Math. Softw.},
month = {jul},
articleno = {13},
numpages = {23}
}

@INPROCEEDINGS{Tacho2018,
  author={Kim, K. and Edwards, H. C. and Rajamanickam, S.},
  booktitle={2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Tacho: Memory-Scalable Task Parallel Sparse Cholesky Factorization}, 
  year={2018},
  doi={10.1109/IPDPSW.2018.00094}
}

@article{Basker2017,
title = {Basker: Parallel sparse LU factorization utilizing hierarchical parallelism and data layouts},
journal = {Parallel Computing},
volume = {68},
pages = {17-31},
year = {2017},
issn = {0167-8191},
doi = {https://doi.org/10.1016/j.parco.2017.06.003},
author = {Joshua D. Booth and Nathan D. Ellingwood and Heidi K. Thornquist and Sivasankaran Rajamanickam}
}

@inproceedings{ShyLUCore2014,
 author = {Thornquist, H. K and Rajamanickam, S.},
 booktitle = {International Conference on High Performance Computing for Computational Science},
 organization = {Springer, Cham},
 pages = {102--111},
 title = {A hybrid approach for parallel transistor-level full-chip circuit simulation},
 year = {2014}
}
